{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running my Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chris/Desktop/pymc3/pymc3/__init__.py'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "import pymc3 as pm\n",
    "pm.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do I need data to evaluate the gradient?\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# Initialize random number generator\n",
    "np.random.seed(123)\n",
    "\n",
    "# True parameter values\n",
    "alpha, sigma = 1, 1; beta = [1, 2.5]\n",
    "\n",
    "# Predictor variable\n",
    "X1 = np.random.randn(100)\n",
    "X2 = np.random.randn(100) * 0.2\n",
    "\n",
    "# Simulate outcome variable\n",
    "Y = alpha + beta[0]*X1 + beta[1]*X2 + np.random.randn(100)*sigma\n",
    "Y=Y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential sampling (1 chains in 1 job)\n",
      "CompoundStep\n",
      ">Metropolis: [beta]\n",
      ">Metropolis: [alpha]\n",
      "100%|██████████| 5500/5500 [00:01<00:00, 3670.90it/s]\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905453\n",
      "[ 0.9458999   2.60061359]\n"
     ]
    }
   ],
   "source": [
    "basic_model2 = pm.Model()\n",
    "with basic_model2:\n",
    "    alpha = pm.Normal(name='alpha',mu=0.0, sd=10.0) \n",
    "    beta = pm.Normal(name='beta', mu=0.0, sd=10.0, shape=2)\n",
    "\n",
    "    mu = alpha + beta[0]*X1 + beta[1]*X2\n",
    "\n",
    "    Y_obs = pm.Normal(name='Y_obs',mu=mu, sd=1.0, observed=Y)\n",
    "\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(5000,step=step,cores=1,chains=1) # switched off parallel for simplifications. \n",
    "\n",
    "print(np.mean(trace['alpha']))\n",
    "print(np.mean(trace['beta'],axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just evaluating the gradient of the prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theano "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/chris/Desktop/pymc3/pymc3/__init__.py'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "import pymc3 as pm\n",
    "pm.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do I need data to evaluate the gradient?\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# Initialize random number generator\n",
    "np.random.seed(123)\n",
    "\n",
    "# True parameter values\n",
    "alpha, sigma = 1, 1; beta = [1, 2.5]\n",
    "\n",
    "# Predictor variable\n",
    "X1 = np.random.randn(100)\n",
    "X2 = np.random.randn(100) * 0.2\n",
    "\n",
    "# Simulate outcome variable\n",
    "Y = alpha + beta[0]*X1 + beta[1]*X2 + np.random.randn(100)*sigma\n",
    "Y=Y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pm.Model()\n",
    "with model:\n",
    "    alpha = pm.Normal(name='alpha',mu=0.0, sd=10.0) \n",
    "    beta = pm.Normal(name='beta', mu=0.0, sd=10.0, shape=2)\n",
    "    \n",
    "    #step = pm.NUTS()\n",
    "    #trace = pm.sample(5000,step=step,cores=1,chains=1)\n",
    "    \n",
    "# this is just the prior model!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.mean(trace['alpha']))\n",
    "# print(np.mean(trace['beta'],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymc3.model.ValueGradFunction at 0x1c1ef036d8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_grad_function = model.logp_dlogp_function([alpha,beta])\n",
    "# this calls \n",
    "# ValueGradFunction(self.logpt, grad_vars, extra_vars, **kwargs)\n",
    "# self.logpt becomes self.cost for the ValueGradFunction\n",
    "\n",
    "# _build_joined is a bit tricky to understand\n",
    "# S.clone(cost, replace=replace) replaces the the input variables in the computation graph for cost. \n",
    "# which are just now in a vector \n",
    "value_grad_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(-9.67462158203125, dtype=float32),\n",
       " array([-0.001, -0.01 , -0.01 ], dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_grad_function._extra_are_set = True\n",
    "value_grad_function(array=np.array([0.1,1.0,1.0]),extra_vars=None)\n",
    "#array = {'alpha':0.1,'beta'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/chris/Desktop/pymc3/pymc3/__init__.py'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "os.environ[\"PYMC_SYMB_BACKEND\"] = \"tensorflow\" \n",
    "import pymc3 as pm\n",
    "pm.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Initialize random number generator\n",
    "np.random.seed(123)\n",
    "\n",
    "# True parameter values\n",
    "alpha, sigma = 1, 1; beta = [1, 2.5]\n",
    "\n",
    "# Predictor variable\n",
    "X1 = np.random.randn(100)\n",
    "X2 = np.random.randn(100) * 0.2\n",
    "\n",
    "# Simulate outcome variable\n",
    "Y = alpha + beta[0]*X1 + beta[1]*X2 + np.random.randn(100)*sigma\n",
    "Y=Y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pm.Model()\n",
    "with model:\n",
    "    alpha = pm.Normal(name='alpha',mu=0.0, sd=10.0,initial_value=0.0) \n",
    "    beta = pm.Normal(name='beta', mu=0.0, sd=10.0,\n",
    "                     initial_value=np.array([1.0,1.0],dtype='float32'), \n",
    "                     shape=2) # this is super annoying that you have to specify the dtype like this.  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /Users/chris/Desktop/pymc3/pymc3/model.py(467)__init__()\n",
      "-> self._theano_function = S.function(grad_vars, [self._cost, grad], givens=givens, **kwargs)\n",
      "(Pdb) grad_vars\n",
      "[<tf.Variable 'alpha:0' shape=() dtype=float32_ref>, <tf.Variable 'beta:0' shape=(2,) dtype=float32_ref>]\n",
      "(Pdb) self._cost\n",
      "<tf.Tensor 'add_6:0' shape=() dtype=float32>\n",
      "(Pdb) grad\n",
      "[<tf.Tensor 'gradients/pow_1_grad/Reshape:0' shape=() dtype=float32>, <tf.Tensor 'gradients/sub_4_grad/Reshape:0' shape=(2,) dtype=float32>]\n",
      "(Pdb) n\n",
      "TypeError: Can not convert a list into a Tensor or Operation.\n",
      "> /Users/chris/Desktop/pymc3/pymc3/model.py(467)__init__()\n",
      "-> self._theano_function = S.function(grad_vars, [self._cost, grad], givens=givens, **kwargs)\n",
      "(Pdb) s\n",
      "--Return--\n",
      "> /Users/chris/Desktop/pymc3/pymc3/model.py(467)__init__()->None\n",
      "-> self._theano_function = S.function(grad_vars, [self._cost, grad], givens=givens, **kwargs)\n",
      "(Pdb) s\n",
      "TypeError: Can not convert a list into a Tensor or Operation.\n",
      "> /Users/chris/Desktop/pymc3/pymc3/model.py(729)logp_dlogp_function()\n",
      "-> return ValueGradFunction(self.logpt, grad_vars, extra_vars, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "value_grad_function = model.logp_dlogp_function([alpha,beta])\n",
    "# this calls \n",
    "# ValueGradFunction(self.logpt, grad_vars, extra_vars, **kwargs)\n",
    "# self.logpt becomes self.cost for the ValueGradFunction\n",
    "\n",
    "# _build_joined is a bit tricky to understand\n",
    "# S.clone(cost, replace=replace) replaces the the input variables in the computation graph for cost. \n",
    "# which are just now in a vector \n",
    "value_grad_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymc3.model.ValueGradFunction at 0x1c2b820898>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_grad_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ValueGradFunction' object has no attribute '_theano_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6b8064ee693c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvalue_grad_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extra_are_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalue_grad_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mextra_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/chris/Desktop/pymc3/pymc3/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, array, grad_out, extra_vars)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mlogp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdlogp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_theano_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrad_out\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlogp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdlogp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ValueGradFunction' object has no attribute '_theano_function'"
     ]
    }
   ],
   "source": [
    "value_grad_function._extra_are_set = True\n",
    "value_grad_function(array=np.array([0.1,1.0,1.0]),extra_vars=None)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
